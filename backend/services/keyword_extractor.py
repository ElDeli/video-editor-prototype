"""
Keyword Extractor Service
Extracts visual keywords from text for scene-per-concept splitting
Uses OpenAI GPT-4o-mini for intelligent visual prompt generation
"""
import re
import os
from typing import List, Dict

class KeywordExtractor:
    def __init__(self):
        # Initialize OpenAI client
        self.openai_client = None
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key:
            try:
                from openai import OpenAI
                self.openai_client = OpenAI(api_key=api_key)
                print("âœ“ OpenAI initialized for visual keyword extraction")
            except Exception as e:
                print(f"âš ï¸ OpenAI initialization failed: {e}")
        else:
            print("âš ï¸ No OPENAI_API_KEY found - using fallback keyword extraction")

        # Keywords that should get their own visual scene
        self.visual_keywords = {
            # People & Professions
            'frau', 'frauen', 'mann', 'mÃ¤nner', 'kind', 'kinder', 'baby',
            'mÃ¤dchen', 'junge', 'jugendliche', 'teenager',
            'wissenschaftler', 'forscher', 'arzt', 'Ã¤rztin', 'professor',

            # Locations & Places
            'haus', 'gartenhaus', 'garten', 'stadt', 'nachbarschaft',
            'labor', 'schule', 'universitÃ¤t', 'krankenhaus',
            'wald', 'berg', 'ozean', 'meer', 'strand', 'wÃ¼ste',

            # Science & Technology
            'kernreaktor', 'reaktor', 'atom', 'radioaktiv', 'strahlung',
            'rauchmelder', 'glÃ¼hbirne', 'experiment',
            'mikroskop', 'teleskop', 'computer', 'roboter',

            # Space & Astronomy
            'galaxie', 'planet', 'stern', 'sterne', 'universum', 'weltall',
            'mond', 'sonne', 'asteroid', 'komet', 'satellit',
            'schwarzes loch', 'urknall', 'big bang',

            # Nature & Animals
            'tier', 'tiere', 'hund', 'katze', 'vogel', 'fisch',
            'lÃ¶we', 'tiger', 'elefant', 'delfin', 'wal',
            'baum', 'blume', 'pflanze', 'wasser', 'feuer',

            # Emotions & Abstract
            'liebe', 'angst', 'freude', 'trauer', 'wut',
            'hoffnung', 'trÃ¤ume', 'albtraum', 'glÃ¼ck',
            'dunkel', 'licht', 'schatten', 'explosion',

            # Energy & Movement
            'energie', 'kraft', 'macht', 'power', 'stÃ¤rke',
            'bewegung', 'motion', 'dynamik', 'tempo',
            'schnell', 'langsam', 'flieÃŸen',

            # Objects & Things
            'buch', 'brief', 'foto', 'bild', 'kamera',
            'auto', 'flugzeug', 'schiff', 'zug', 'rakete',
            'geld', 'gold', 'diamant', 'krone', 'schwert',

            # Events & Actions
            'evakuierung', 'evakuieren', 'unfall', 'katastrophe',
            'krieg', 'frieden', 'revolution', 'entdeckung',
            'geburt', 'tod', 'hochzeit', 'feier', 'party',

            # Time
            'vergangenheit', 'zukunft', 'heute', 'gestern', 'morgen',
            'jahrhundert', 'jahrzehnt', 'jahr', 'nacht', 'tag'
        }

        # Emotional/important words (uppercase, numbers, exclamation)
        self.emphasis_patterns = [
            r'\b[A-ZÃ„Ã–Ãœ]{3,}\b',  # ALL CAPS words
            r'\d{3,}',  # Numbers with 3+ digits
            r'[!?]{2,}',  # Multiple punctuation
        ]

    def extract_visual_scenes(self, text: str) -> List[Dict]:
        """
        Extract scenes based on COMPLETE SENTENCES (like in screenshots)

        Strategy: 1 scene = 1 full sentence
        - TTS reads the FULL sentence (in ORIGINAL language)
        - Visual prompt is DYNAMICALLY extracted from sentence content
        - EVERY scene gets an AI-generated image based on the sentence meaning
        - Like Instagram Reels / YouTube Shorts style

        IMPORTANT: The 'script' field preserves the ORIGINAL language.
        Only the 'visual_search' field is generated by AI (for image generation).
        """
        scenes = []

        # Split into sentences
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.strip() for s in sentences if s.strip()]

        print(f"\nðŸ“ Auto-creating {len(sentences)} scenes from script...")
        print(f"   Original language will be PRESERVED in script field\n")

        for idx, sentence in enumerate(sentences, 1):
            # DYNAMIC: Extract visual prompt directly from sentence
            # This is ONLY used for image generation, NOT for TTS
            visual_prompt = self._extract_visual_concept(sentence)

            print(f"   Scene {idx}: Script='{sentence[:40]}...' | Visual='{visual_prompt}'")

            scenes.append({
                'script': sentence,  # FULL SENTENCE for TTS (ORIGINAL LANGUAGE)
                'keywords': [],  # Not needed anymore - we use dynamic extraction
                'scene_type': 'keyword',  # ALWAYS keyword type
                'visual_search': visual_prompt  # Dynamic visual concept (for images only)
            })

        print(f"âœ“ Created {len(scenes)} scenes with original language preserved\n")
        return scenes

    def _find_keywords(self, text: str) -> List[str]:
        """Find visual keywords in text"""
        text_lower = text.lower()
        found = []

        for keyword in self.visual_keywords:
            if keyword in text_lower:
                found.append(keyword)

        # Also check for emphasis patterns
        for pattern in self.emphasis_patterns:
            matches = re.findall(pattern, text)
            if matches:
                found.extend(matches)

        return list(set(found))  # Remove duplicates

    def _select_best_keyword(self, keywords: List[str], sentence: str) -> str:
        """
        Select the most visually striking and relevant keyword from a list

        Priority order:
        1. Celestial/Space objects (universum, galaxie, stern, planet, etc.)
        2. Natural elements (feuer, wasser, licht, explosion)
        3. Powerful concepts (energie, kraft, mut)
        4. Emotions (liebe, angst, freude, wut)
        5. People/Objects (frau, mann, gold)
        6. Everything else
        """
        if not keywords:
            return keywords[0] if keywords else None

        sentence_lower = sentence.lower()

        # Define priority tiers
        priority_tiers = {
            1: ['universum', 'galaxie', 'stern', 'sterne', 'planet', 'mond', 'sonne',
                'weltall', 'schwarzes loch', 'urknall', 'komet', 'asteroid'],
            2: ['feuer', 'wasser', 'licht', 'explosion', 'blitz', 'donner'],
            3: ['energie', 'kraft', 'macht', 'power', 'strahlung'],
            4: ['liebe', 'angst', 'freude', 'wut', 'hoffnung', 'mut'],
            5: ['gold', 'diamant', 'krone', 'schatz'],
        }

        # Check each priority tier
        for tier in sorted(priority_tiers.keys()):
            for keyword in keywords:
                keyword_lower = keyword.lower()
                if keyword_lower in priority_tiers[tier]:
                    return keyword

        # If no priority keyword found, choose based on position in sentence
        # Keywords appearing earlier in the sentence are usually more important
        keyword_positions = {}
        for keyword in keywords:
            pos = sentence_lower.find(keyword.lower())
            if pos != -1:
                keyword_positions[keyword] = pos

        if keyword_positions:
            # Return keyword that appears first in sentence
            return min(keyword_positions, key=keyword_positions.get)

        # Fallback: return first keyword
        return keywords[0]

    def _create_balanced_scenes(self, sentence: str, keywords: List[str]) -> List[Dict]:
        """
        Create balanced scenes from sentence with multiple keywords
        Keep phrases grammatically correct
        """
        scenes = []
        words = sentence.split()

        # Find keyword positions
        keyword_positions = []
        for idx, word in enumerate(words):
            word_lower = word.lower().strip('.,!?;:')
            if any(kw in word_lower for kw in keywords):
                keyword_positions.append((idx, word_lower))

        if not keyword_positions:
            return [{'script': sentence, 'keywords': keywords, 'scene_type': 'text', 'visual_search': None}]

        # Split into chunks around keywords
        chunks = []
        start = 0

        for pos, keyword in keyword_positions:
            # Include 2-3 words before keyword for context
            chunk_start = max(start, pos - 2)
            # Include 2-3 words after keyword
            chunk_end = min(len(words), pos + 3)

            chunk = ' '.join(words[chunk_start:chunk_end])
            chunks.append({
                'script': chunk,
                'keywords': [keyword],
                'scene_type': 'keyword',
                'visual_search': keyword
            })

            start = chunk_end

        # Add remaining words if any
        if start < len(words):
            remaining = ' '.join(words[start:])
            if len(remaining.split()) >= 3:
                chunks.append({
                    'script': remaining,
                    'keywords': [],
                    'scene_type': 'text',
                    'visual_search': None
                })

        return chunks

    def _create_keyword_focused_scenes(self, sentence: str, keywords: List[str]) -> List[Dict]:
        """Create scenes focusing on the keyword with context"""
        keyword = keywords[0]
        words = sentence.split()

        # Find keyword position
        keyword_pos = None
        for idx, word in enumerate(words):
            if keyword in word.lower():
                keyword_pos = idx
                break

        if keyword_pos is None:
            return [{'script': sentence, 'keywords': keywords, 'scene_type': 'text', 'visual_search': None}]

        scenes = []

        # Before keyword (if substantial)
        if keyword_pos > 3:
            before = ' '.join(words[:keyword_pos])
            scenes.append({
                'script': before,
                'keywords': [],
                'scene_type': 'text',
                'visual_search': None
            })

        # Keyword with context (2 words before + keyword + 2 words after)
        context_start = max(0, keyword_pos - 2)
        context_end = min(len(words), keyword_pos + 3)
        keyword_context = ' '.join(words[context_start:context_end])
        scenes.append({
            'script': keyword_context,
            'keywords': [keyword],
            'scene_type': 'keyword',
            'visual_search': keyword
        })

        # After keyword (if substantial)
        if context_end < len(words) - 2:
            after = ' '.join(words[context_end:])
            scenes.append({
                'script': after,
                'keywords': [],
                'scene_type': 'text',
                'visual_search': None
            })

        return scenes

    def _split_by_clauses(self, sentence: str) -> List[Dict]:
        """Split long sentence by clauses (commas, dashes)"""
        # Split by commas and dashes
        clauses = re.split(r'[,â€“â€”]+', sentence)
        clauses = [c.strip() for c in clauses if c.strip() and len(c.split()) >= 3]

        scenes = []
        for clause in clauses:
            clause_keywords = self._find_keywords(clause)
            scenes.append({
                'script': clause,
                'keywords': clause_keywords,
                'scene_type': 'keyword' if clause_keywords else 'text',
                'visual_search': clause_keywords[0] if clause_keywords else None
            })

        return scenes if scenes else [{'script': sentence, 'keywords': [], 'scene_type': 'text', 'visual_search': None}]

    def _create_keyword_scenes(self, sentence: str, keywords: List[str]) -> List[Dict]:
        """
        Create multiple scenes from a sentence with keywords

        Example:
        "Die Frau sah den Urknall" ->
        1. Scene: "Die Frau" (image: woman)
        2. Scene: "sah den" (text only)
        3. Scene: "Urknall" (image: big bang)
        """
        scenes = []
        words = sentence.split()
        current_chunk = []

        for word in words:
            word_lower = word.lower().strip('.,!?;:')
            is_keyword = any(kw in word_lower for kw in keywords)

            if is_keyword:
                # Finish previous chunk if exists
                if current_chunk:
                    scenes.append({
                        'script': ' '.join(current_chunk),
                        'keywords': [],
                        'scene_type': 'text',
                        'visual_search': None
                    })
                    current_chunk = []

                # Create keyword scene
                scenes.append({
                    'script': word,
                    'keywords': [word_lower],
                    'scene_type': 'keyword',
                    'visual_search': word_lower
                })
            else:
                current_chunk.append(word)

        # Add remaining chunk
        if current_chunk:
            chunk_text = ' '.join(current_chunk)
            # Check if chunk has any keywords
            chunk_keywords = self._find_keywords(chunk_text)
            scenes.append({
                'script': chunk_text,
                'keywords': chunk_keywords,
                'scene_type': 'keyword' if chunk_keywords else 'text',
                'visual_search': chunk_keywords[0] if chunk_keywords else None
            })

        return scenes

    def _extract_visual_concept(self, sentence: str) -> str:
        """
        INTELLIGENTLY extract visual concept using OpenAI GPT-4o-mini

        Uses AI to understand the sentence and generate a precise,
        visually descriptive prompt for optimal image generation.

        IMPORTANT: This is ONLY for image generation. The original sentence
        remains unchanged in the 'script' field for TTS.

        Falls back to simple extraction if OpenAI is unavailable.

        Returns: A concise visual prompt for AI image generation
        """
        # Try OpenAI-powered extraction with Multi-Keyword approach (3 variations)
        if self.openai_client:
            try:
                # Generate 3 keyword variations with different creativity levels
                temperatures = [0.3, 0.7, 1.0]  # Conservative, Balanced, Creative
                keywords = []

                system_prompt = """You are a visual prompt generator for AI image generation (Flux models).
Your task: Extract the CORE VISUAL CONCEPT from a sentence for creating a CONCRETE, SPECIFIC image.

ðŸ”´ CRITICAL: ALWAYS output in ENGLISH, regardless of input language!
Flux AI models work BEST with English prompts for highest quality results.

PRIORITY RULES (in order):
1. CONCRETE elements FIRST: people, objects, animals, places, nature
2. AVOID abstract concepts (love, time, hope) unless no concrete element exists
3. Extract the MAIN SUBJECT + ACTION or SETTING
4. Be hyper-SPECIFIC (not "light" but "glowing golden light flooding dark room")

Output Rules:
1. Output ONLY 4-10 words in ENGLISH
2. Use photographic/cinematic descriptive language
3. Focus on what CAN BE PHOTOGRAPHED or PAINTED
4. NO explanations, NO quotes, JUST the visual prompt
5. Keep it natural and concrete (avoid generic adjectives)

Examples:

Input: "Das Licht, das nie erlosch" (German)
Bad: "eternal light" (too abstract)
Good: "bright glowing golden light in dark cave"

Input: "Tief im Universum gibt es Sterne, die lÃ¤ngst erloschen sind" (German)
Bad: "dead stars" (too generic)
Good: "fading stars in deep black universe"

Input: "Eine Frau entdeckte ein Geheimnis" (German)
Bad: "secret" (not visual)
Good: "woman opening old mysterious chest"

Input: "Klimaforschung & Geoengineering â€“ kÃ¼nstliche Wolken" (German)
Good: "scientists generating artificial clouds in laboratory"

Input: "Liebe verbindet Menschen Ã¼ber Grenzen hinweg" (German)
Bad: "love" (too abstract)
Good: "two people holding hands across border"

Input: "Scientists discovered a fascinating alpine village" (English)
Good: "scientists in hiking gear discovering remote alpine village"
"""

                print(f"ðŸŽ¨ Generating 3 keyword variations for: '{sentence[:50]}...'")

                for temp in temperatures:
                    response = self.openai_client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": sentence}
                        ],
                        temperature=temp,
                        max_tokens=30
                    )
                    keyword = response.choices[0].message.content.strip()
                    keywords.append(keyword)
                    print(f"   â€¢ Temp {temp}: '{keyword}'")

                # Select best keyword: Prefer most specific (longest with more details)
                # This ensures concrete, detailed descriptions over generic ones
                best_keyword = max(keywords, key=lambda k: len(k))

                print(f"âœ“ Selected best: '{best_keyword}' (length: {len(best_keyword)})")
                return best_keyword

            except Exception as e:
                print(f"âš ï¸ OpenAI extraction failed: {e}, using fallback")

        # Fallback: Simple extraction (original logic)
        words = sentence.lower().split()
        stopwords = {
            'der', 'die', 'das', 'den', 'dem', 'des', 'ein', 'eine', 'einen', 'einem',
            'und', 'oder', 'aber', 'ist', 'sind', 'war', 'waren', 'wird', 'werden',
            'hat', 'haben', 'auf', 'in', 'von', 'zu', 'mit', 'fÃ¼r', 'Ã¼ber', 'durch',
            'bei', 'aus', 'an', 'als', 'wie', 'wenn', 'dass', 'dann', 'auch', 'noch',
            'nicht', 'nur', 'sich', 'du', 'deine', 'dein', 'ich', 'wir', 'mein', 'meine'
        }

        meaningful_words = [w.strip('.,!?;:â€“â€”') for w in words if w not in stopwords and len(w) > 2]

        if len(meaningful_words) >= 2:
            return ' '.join(meaningful_words[:3])
        elif len(meaningful_words) == 1:
            return meaningful_words[0]
        else:
            clean_sentence = sentence.strip('.,!?;:â€“â€”').lower()
            return ' '.join(clean_sentence.split()[:5])

    def suggest_visual_search(self, keyword: str) -> str:
        """
        Suggest search query for stock images/videos
        Returns English translation for better stock results
        """
        # German to English mapping for common keywords
        translations = {
            'frau': 'woman portrait',
            'mann': 'man portrait',
            'kind': 'child',
            'wissenschaftler': 'scientist lab',
            'kernreaktor': 'nuclear reactor',
            'gartenhaus': 'garden shed',
            'radioaktiv': 'radioactive warning',
            'nachbarschaft': 'neighborhood houses',
            'urknall': 'big bang universe',
            'galaxie': 'galaxy space',
            'universum': 'universe cosmos',
            'explosion': 'explosion blast',
            'feuer': 'fire flames',
            'wasser': 'water ocean',
            'dunkel': 'dark night',
            'licht': 'bright light',
            # Add more as needed
        }

        keyword_lower = keyword.lower().strip()
        return translations.get(keyword_lower, keyword_lower)
